import torch
from torch import optim #optim은 최적화 함수가 포함돼 있는 모듈이다. 

x = torch.FloatTensor( #파이토치를 이용하기 때문에 ndarray형식이 아닌 파이토치 형식으로!
    [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10],
    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],
    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]]  
) #단변량 형태
y = torch.FloatTensor(
    [[0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],
    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],
    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]]
)

weight = torch.zeros(1, requires_grad=True) #torch.zeros는 0의 값을 갖는 텐서를 생성
bias = torch.zeros(1, requires_grad=True) #requires_grad는 모든 텐서에 대한 연산을 추적하여 역전파 메서드를 호출해 기울기를 계산하고 저장함.
learning_rate=0.001

optimizer=optim.SGD([weight,bias],lr=learning_rate) #최적화 선언 방식을 확률적 경사 하강법을 이용했다. 변수와 학습률로 최적화

for epoch in range(10000):
    hypothesis = weight * x + bias
    cost = torch.mean((hypothesis - y) ** 2)
 
    #가중치와 편향 갱신
    optimizer.zero_grad() #기울기를 0으로 초기화
    cost.backward() #역전파 수행, 매개변수들의 기울기 새로 계산 
    optimizer.step() #학습률 반영한 확률적 경사 하강법 연산

    
    if (epoch + 1) % 1000 == 0:
        print(f"Epoch : {epoch+1:4d}, Weight : {weight.item():.3f}, Bias : {bias.item():.3f}, Cost : {cost:.3f}")
